{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2693418-cbf8-45f9-a867-f5cfa83eb94a",
   "metadata": {},
   "source": [
    "# Sieci neuronowe i deep learning - Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35789f6f-1aa2-474d-bb6c-2b0ef659b472",
   "metadata": {},
   "source": [
    "# Gotowe modele CNN i transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa91e-f3b6-472a-93b5-ac274bfc5633",
   "metadata": {},
   "source": [
    "## Ćwiczenie 1\n",
    "\n",
    "- Zaimportuj zbiór danych do klasyfikacji obrazów z zasobów tensorflow (np. cats vs dogs) (https://www.tensorflow.org/datasets/catalog/cats_vs_dogs). \n",
    "- Wyświetl kilka przykładowych obrazów\n",
    "- Przeskaluj piksele na obrazach do zakresu [0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d88e0f-633d-4e20-b613-154598798128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nazwa_zbioru = 'cats_vs_dogs'\n",
    "splt = ['train[:80%]', 'train[80%:]']\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(nazwa_zbioru, split=splt, shuffle_files=True, as_supervised=True, with_info=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260e25c-4b33-4f7f-9302-9c6cd32aadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(zbior, rows=3, cols=3):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, (image, label) in enumerate(zbior.take(rows*cols)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(image.numpy())\n",
    "        plt.title(ds_info.features['label'].int2str(label))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d6ec3-fe7d-4e46-a677-cff5c8d25e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "#użyj metody .map()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e25ee-c522-417f-9045-cfa269c77a19",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2\n",
    "\n",
    " - Stwórz model sieci konwolucyjnej wefług wymyślonej przez siebie architektury\n",
    " - Skompiluj model\n",
    " - Wytrenuj model na danych treningowych, narysuj krzywe uczenia dla funkcji strat i dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995af50-0392-41d4-9d01-0aa79082659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596174cd-62c2-4fc5-98eb-1a6ee22b9c5f",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3\n",
    "\n",
    "- Wybierz pretrenowany model głębokiej sieci neuronowej z listy: https://www.tensorflow.org/api_docs/python/tf/keras/applications (np. vgg16)\n",
    "- Przygotuj funkcję \"preprocess\", która będzie zmieniać rozmiary obrazów do wymaganych ((224, 224) w przypadku vgg16), oraz zastosuje funkcję preprocess_input, przygotowującą dane odpowiednio do dnego modelu. Funkcja ta następnie zostanie wykorzystana w metodzie .map zbioru danych\n",
    "- utwórz bazowy model (np. tf.keras.applications.VGG16), z wagami wytrenwanymi na zbiorze 'imagenet', bez załączania górnych warstw klasyfikacyjnych (https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16)\n",
    "- zablokuj możliwość trenowania parametrów w modelu bazowym\n",
    "- stówrz cały model klasyfikacyjny, dołączając do modelu bazowego swoje warstwy, na końcu klasyfikujace do tylu klas ile jest w wybranym w ćwizeniu 1 problemie\n",
    "- skompiluj model, pamiętając, aby dobrać mniejszy niż standardowo krok uczenia w optymalizatorze (np. tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
    "- wytrenuj model i wyrysuj krzywe uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bffeaf-fef5-4cd6-98be-0270781adcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def preprocess(image, label):\n",
    "    ######\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f32bc-7b5b-4f22-b296-f14fd3f127bd",
   "metadata": {},
   "source": [
    "# Ćwiczenie 4\n",
    "\n",
    "- Uwolnij parametry w kilku ostatnich warstwach modelu bazowego, umoliwiającich trenowanie (skorzystaj z pola .layers modelu bazowego).\n",
    "- Skompiluj model, jeszcze raz zmiejszając parametr uczenia.\n",
    "- Wytrenuj model i porównaj ze sobą wyniki uzyskane w ćwiczeniach 2, 3 i 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
