{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2693418-cbf8-45f9-a867-f5cfa83eb94a",
   "metadata": {},
   "source": [
    "# Sieci neuronowe i deep learning - Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35789f6f-1aa2-474d-bb6c-2b0ef659b472",
   "metadata": {},
   "source": [
    "# MLP w Tensorflow, cz. II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa91e-f3b6-472a-93b5-ac274bfc5633",
   "metadata": {},
   "source": [
    "## Cwiczenie 1\n",
    "\n",
    "- Zaimportuj zbiór danych korzystając z funkcji tf.keras.datasets.mnist.load_data: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
    "- utwórz obiekty tf.data.Dataset (https://www.tensorflow.org/api_docs/python/tf/data/Dataset), jeden dla zbioru treningowego, drugi dla zbioru testowego, korzystając z metody from_tensor_slices\n",
    "- użyj funkcji: shuffle do wymiaszania danych, batch do pogrupowania ich w paczki\n",
    "- korzystając z metody take, pobierz kilka pierwszych danych, przekonwertuj do macierzy numpy i wyświetl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d88e0f-633d-4e20-b613-154598798128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Załadowanie danych MNIST\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# Tworzenie obiektów tf.data.Dataset dla zbioru treningowego i testowego\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Shuffle i batchowanie danych\n",
    "train_ds = train_ds.shuffle(buffer_size=10000).batch(32)\n",
    "test_ds = test_ds.batch(32)\n",
    "\n",
    "# Pobranie kilku pierwszych próbek z train_ds i konwersja do macierzy numpy\n",
    "for images, labels in train_ds.take(1):  # Weźmy tylko pierwszą paczkę danych\n",
    "    images_np = images.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "# Wyświetlenie kilku przykładowych obrazów\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(images_np[i], cmap='gray')\n",
    "    plt.title(f'Etykieta: {labels_np[i]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e25ee-c522-417f-9045-cfa269c77a19",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2\n",
    "\n",
    " - Stwórz własną warstwę neuronową, implementując klasę dziedziczącą po tf.keras.layers.Layer (https://www.tensorflow.org/tutorials/customization/custom_layers). Klasa musi zawierać metodę __init__(self, parametry), build(self, input_shape), w której zdefiniujemy parametry przy pomocy metody self.add_weight, oraz metody def call(self, inputs) do zdefiniowania działania warstwy\n",
    " - Stwórz model sieci neuronowej, wykorzystujący nowy typ warstwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec933a62-69d2-4a12-8bc9-92ac785024bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_layer (\u001b[38;5;33mCustomLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "# Definicja niestandardowej warstwy\n",
    "class CustomLayer(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Dodajemy wagę i przesunięcie (bias)\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=\"random_normal\",\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=\"zeros\",\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Zastosowanie transformacji liniowej: y = x * W + b\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "# Tworzenie modelu sekwencyjnego wykorzystującego niestandardową warstwę\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Rozwijamy obraz 28x28 na wektor\n",
    "    CustomLayer(64),                       # Nasza niestandardowa warstwa z 64 jednostkami\n",
    "    layers.Activation('relu'),             # Aktywacja ReLU\n",
    "    layers.Dense(10, activation='softmax') # Warstwa wyjściowa z 10 klasami\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Wyświetlenie struktury modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99516b-473d-4a37-bbc4-afff62747d01",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3\n",
    "\n",
    "- Utwórz obiekt odpowiedniej funkcji straty oraz wybranego optymalizatora\n",
    "- Utwórz obiekty odpowiednich metryk, zarówno dla zbioru treningowego jak i testowego\n",
    "- Stworz funkcję do trenowania train_step(x,y) z wykorzystaniem obiektu tf.GradientTape, do monitorowania gradientów. Wykorzystaj funkcję \"gradient\" tego obiektu do wyznaczenia gradientów funkcji straty względem parametrów modelu (model.trainable_variables) oraz metodę \"apply_gradients\" optymalizatora do modyfikacji tych parametrów. Opatrz funkcję dekoratorem @tf.function\n",
    "- Utwórz podobną funkcję dla kroku testowania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a98ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Step 0, Loss: 2.2612411975860596, Train Accuracy: 0.1875\n",
      "Step 100, Loss: 0.48317402601242065, Train Accuracy: 0.7336015105247498\n",
      "Step 200, Loss: 0.16578122973442078, Train Accuracy: 0.8011505007743835\n",
      "Step 300, Loss: 0.26816582679748535, Train Accuracy: 0.8343023061752319\n",
      "Step 400, Loss: 0.5244916081428528, Train Accuracy: 0.8527898788452148\n",
      "Step 500, Loss: 0.28649041056632996, Train Accuracy: 0.8647704720497131\n",
      "Step 600, Loss: 0.3789319396018982, Train Accuracy: 0.8739080429077148\n",
      "Step 700, Loss: 0.34990981221199036, Train Accuracy: 0.8802157640457153\n",
      "Step 800, Loss: 0.19603581726551056, Train Accuracy: 0.8851435780525208\n",
      "Step 900, Loss: 0.2861492931842804, Train Accuracy: 0.8903648853302002\n",
      "Step 1000, Loss: 0.09428104758262634, Train Accuracy: 0.8945741653442383\n",
      "Step 1100, Loss: 0.2261473536491394, Train Accuracy: 0.8979620933532715\n",
      "Step 1200, Loss: 0.1591455191373825, Train Accuracy: 0.9005516171455383\n",
      "Step 1300, Loss: 0.5335155725479126, Train Accuracy: 0.9030073285102844\n",
      "Step 1400, Loss: 0.3259914517402649, Train Accuracy: 0.9055362343788147\n",
      "Step 1500, Loss: 0.2820199728012085, Train Accuracy: 0.9076449275016785\n",
      "Step 1600, Loss: 0.169672891497612, Train Accuracy: 0.9101147651672363\n",
      "Step 1700, Loss: 0.12289353460073471, Train Accuracy: 0.912239134311676\n",
      "Step 1800, Loss: 0.16710971295833588, Train Accuracy: 0.9140581488609314\n",
      "End of epoch 0, Training Accuracy: 0.9156666398048401\n",
      "Start testing\n",
      "Step 0, Test Loss: 0.1908312439918518, Test Accuracy: 0.96875\n",
      "Step 100, Test Loss: 0.19530296325683594, Test Accuracy: 0.9207921028137207\n",
      "Step 200, Test Loss: 0.130926251411438, Test Accuracy: 0.928016185760498\n",
      "Step 300, Test Loss: 0.1256544291973114, Test Accuracy: 0.9418604373931885\n",
      "End of epoch 0, Test Accuracy: 0.9401000142097473\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Definicja modelu z warstwą Flatten\n",
    "class SimpleModel(Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.flatten = layers.Flatten()  # Dodajemy warstwę Flatten\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.dense2 = layers.Dense(10, activation='softmax')  # Warstwa wyjściowa dla klasyfikacji\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)  # Spłaszczenie wejścia\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Utwórz obiekt funkcji straty i optymalizatora\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)  # 'from_logits=False' ponieważ używamy softmax\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Utwórz obiekty metryk\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Funkcja do trenowania modelu (jeden krok)\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Obliczamy wyjście modelu i stratę\n",
    "        y_pred = model(x, training=True)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "\n",
    "    # Obliczamy gradienty\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Aktualizujemy wagi modelu\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Aktualizujemy metrykę dokładności dla treningu\n",
    "    train_acc_metric.update_state(y, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Funkcja do testowania modelu (jeden krok)\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    # Obliczamy wyjście modelu\n",
    "    y_pred = model(x, training=False)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "\n",
    "    # Aktualizujemy metrykę dokładności dla testu\n",
    "    test_acc_metric.update_state(y, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Przykładowe dane\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Przekształcamy dane w kształt [batch_size, 28, 28, 1] (dodajemy wymiar kanału)\n",
    "x_train = x_train[..., tf.newaxis]  # Dodanie wymiaru kanału\n",
    "x_test = x_test[..., tf.newaxis]    # Dodanie wymiaru kanału\n",
    "\n",
    "# Normalizacja danych wejściowych do zakresu [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Tworzymy model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Tworzymy Dataset dla treningu i testu\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# Trening - 1 epoka\n",
    "for epoch in range(1):\n",
    "    print(\"Start training\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds):\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy()}, Train Accuracy: {train_acc_metric.result().numpy()}\")\n",
    "\n",
    "    # Wyświetlamy dokładność treningową po epokach\n",
    "    print(f\"End of epoch {epoch}, Training Accuracy: {train_acc_metric.result().numpy()}\")\n",
    "\n",
    "# Testowanie - 1 epoka\n",
    "for epoch in range(1):\n",
    "    print(\"Start testing\")\n",
    "    for step, (x_batch, y_batch) in enumerate(test_ds):\n",
    "        loss = test_step(x_batch, y_batch)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Test Loss: {loss.numpy()}, Test Accuracy: {test_acc_metric.result().numpy()}\")\n",
    "\n",
    "    # Wyświetlamy dokładność testową po epokach\n",
    "    print(f\"End of epoch {epoch}, Test Accuracy: {test_acc_metric.result().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596174cd-62c2-4fc5-98eb-1a6ee22b9c5f",
   "metadata": {},
   "source": [
    "## Ćwiczenie 4\n",
    "\n",
    " - Zaimplementuj główną pętlę uczenia modelu dla zadanej liczby epok. Na starcie każdej epoki zresetuj ustawienia obiektów metryk (metodą reset_state), następnie wykonaj kroki uczenia na batchu ze zbioru treningowego oraz testowania na batchu ze zbioru testowego (wykorzystaj zbiory z ćwiczenia nr 1), oraz wyświetl lub zapisz do listy wyniki funkcji straty i dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bffeaf-fef5-4cd6-98be-0270781adcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 1/5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SparseCategoricalAccuracy' object has no attribute 'reset_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoka \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Reset metryk na początku każdej epoki\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrain_acc_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_states\u001b[49m()\n\u001b[0;32m     16\u001b[0m test_acc_metric\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Pętla uczenia dla zbioru treningowego\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparseCategoricalAccuracy' object has no attribute 'reset_states'"
     ]
    }
   ],
   "source": [
    "# Parametry\n",
    "EPOCHS = 5  # Możesz ustawić dowolną liczbę epok\n",
    "\n",
    "# Listy do przechowywania wyników dla każdej epoki\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "test_loss_results = []\n",
    "test_accuracy_results = []\n",
    "\n",
    "# Główna pętla uczenia\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoka {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # Reset metryk na początku każdej epoki\n",
    "    # train_acc_metric.reset_states()\n",
    "    # test_acc_metric.reset_states()\n",
    "\n",
    "    # Pętla uczenia dla zbioru treningowego\n",
    "    for x_batch_train, y_batch_train in train_ds:\n",
    "        train_loss = train_step(x_batch_train, y_batch_train)\n",
    "    \n",
    "    # Obliczamy dokładność i stratę dla zbioru treningowego na koniec epoki\n",
    "    train_accuracy = train_acc_metric.result().numpy()\n",
    "    train_loss_results.append(train_loss.numpy())\n",
    "    train_accuracy_results.append(train_accuracy)\n",
    "\n",
    "    # Pętla testowania dla zbioru testowego\n",
    "    for x_batch_test, y_batch_test in test_ds:\n",
    "        test_loss = test_step(x_batch_test, y_batch_test)\n",
    "\n",
    "    # Obliczamy dokładność i stratę dla zbioru testowego na koniec epoki\n",
    "    test_accuracy = test_acc_metric.result().numpy()\n",
    "    test_loss_results.append(test_loss.numpy())\n",
    "    test_accuracy_results.append(test_accuracy)\n",
    "\n",
    "    # Wyświetlenie wyników na koniec każdej epoki\n",
    "    print(f\"Epoka {epoch + 1}, Trening - Strata: {train_loss.numpy()}, Dokładność: {train_accuracy}\")\n",
    "    print(f\"Epoka {epoch + 1}, Testowanie - Strata: {test_loss.numpy()}, Dokładność: {test_accuracy}\")\n",
    "\n",
    "print(\"Trening zakończony.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243243b-f81f-430a-8917-cf97e51e3d5e",
   "metadata": {},
   "source": [
    "# OPTYMALIZACJA HIPERPARAMETRÓW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a33caa-8309-4b51-a13a-504a41bdf0dc",
   "metadata": {},
   "source": [
    "## Ćwiczenie 5\n",
    "\n",
    "- zaimportuj pakiet keras-tuner \n",
    "- Utwórz klasę dziedziczącą po klasie kt.HyperModel (https://keras.io/api/keras_tuner/hypermodels/), której metodą jest metoda def build(self, hp), zwracająca model generowany (i skompilowany) z wykorzystaniem frameworku Keras. parametr \"hp\" pozwala na definiowanie przedziałów poszukiwań parametrów modelu (np. liczby neuronów w warstwie)\n",
    "- Utwórz obiekt tunera (np. kt.RandomSearch, https://keras.io/api/keras_tuner/tuners/) \n",
    "- Naucz model i znajdź optymalne wartości hiperparametrów metodą tuner.search (przyjmuje takie same parametry jak metoda \"fit\" przy trenowaniu modeli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc219ac-a3bc-44d5-96d0-697ee2315e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, Model, optimizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ładowanie i przygotowanie danych MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalizacja\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Klasa HyperModel\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Model()\n",
    "        inputs = layers.Input(shape=(28, 28))\n",
    "        x = layers.Flatten()(inputs)\n",
    "        \n",
    "        # Pierwsza warstwa - liczba neuronów poszukiwana między 32 a 512\n",
    "        x = layers.Dense(\n",
    "            units=hp.Int('units1', min_value=32, max_value=512, step=32), \n",
    "            activation='relu'\n",
    "        )(x)\n",
    "        \n",
    "        # Druga warstwa - liczba neuronów poszukiwana między 32 a 512\n",
    "        x = layers.Dense(\n",
    "            units=hp.Int('units2', min_value=32, max_value=512, step=32),\n",
    "            activation='relu'\n",
    "        )(x)\n",
    "        \n",
    "        # Wyjście\n",
    "        outputs = layers.Dense(10, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Kompilacja modelu\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(\n",
    "                hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "            ),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# Obiekt tunera\n",
    "tuner = kt.RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=5,  # Maksymalna liczba prób poszukiwań\n",
    "    executions_per_trial=3,  # Liczba wykonanych prób dla każdego zestawu hiperparametrów\n",
    "    directory='my_dir',  # Katalog do zapisu wyników\n",
    "    project_name='mnist_tuning'  # Nazwa projektu\n",
    ")\n",
    "\n",
    "# Wyszukiwanie optymalnych wartości hiperparametrów\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Wyświetlenie najlepszych hiperparametrów\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Najlepsze hiperparametry: Jednostki warstwy 1: {best_hps.get('units1')}, Jednostki warstwy 2: {best_hps.get('units2')}, Learning rate: {best_hps.get('learning_rate')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
