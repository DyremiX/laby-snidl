{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2693418-cbf8-45f9-a867-f5cfa83eb94a",
   "metadata": {},
   "source": [
    "# Sieci neuronowe i deep learning - Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35789f6f-1aa2-474d-bb6c-2b0ef659b472",
   "metadata": {},
   "source": [
    "# MLP w Tensorflow, cz. II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa91e-f3b6-472a-93b5-ac274bfc5633",
   "metadata": {},
   "source": [
    "## Cwiczenie 1\n",
    "\n",
    "- Zaimportuj zbiór danych korzystając z funkcji tf.keras.datasets.mnist.load_data: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
    "- utwórz obiekty tf.data.Dataset (https://www.tensorflow.org/api_docs/python/tf/data/Dataset), jeden dla zbioru treningowego, drugi dla zbioru testowego, korzystając z metody from_tensor_slices\n",
    "- użyj funkcji: shuffle do wymiaszania danych, batch do pogrupowania ich w paczki\n",
    "- korzystając z metody take, pobierz kilka pierwszych danych, przekonwertuj do macierzy numpy i wyświetl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d88e0f-633d-4e20-b613-154598798128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Załadowanie danych MNIST\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# Tworzenie obiektów tf.data.Dataset dla zbioru treningowego i testowego\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Shuffle i batchowanie danych\n",
    "train_ds = train_ds.shuffle(buffer_size=10000).batch(32)\n",
    "test_ds = test_ds.batch(32)\n",
    "\n",
    "# Pobranie kilku pierwszych próbek z train_ds i konwersja do macierzy numpy\n",
    "for images, labels in train_ds.take(1):  # Weźmy tylko pierwszą paczkę danych\n",
    "    images_np = images.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "# Wyświetlenie kilku przykładowych obrazów\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(images_np[i], cmap='gray')\n",
    "    plt.title(f'Etykieta: {labels_np[i]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e25ee-c522-417f-9045-cfa269c77a19",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2\n",
    "\n",
    " - Stwórz własną warstwę neuronową, implementując klasę dziedziczącą po tf.keras.layers.Layer (https://www.tensorflow.org/tutorials/customization/custom_layers). Klasa musi zawierać metodę __init__(self, parametry), build(self, input_shape), w której zdefiniujemy parametry przy pomocy metody self.add_weight, oraz metody def call(self, inputs) do zdefiniowania działania warstwy\n",
    " - Stwórz model sieci neuronowej, wykorzystujący nowy typ warstwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec933a62-69d2-4a12-8bc9-92ac785024bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " custom_layer (CustomLayer)  (None, 64)                50240     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "# Definicja niestandardowej warstwy\n",
    "class CustomLayer(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Dodajemy wagę i przesunięcie (bias)\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=\"random_normal\",\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=\"zeros\",\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Zastosowanie transformacji liniowej: y = x * W + b\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "# Tworzenie modelu sekwencyjnego wykorzystującego niestandardową warstwę\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Rozwijamy obraz 28x28 na wektor\n",
    "    CustomLayer(64),                       # Nasza niestandardowa warstwa z 64 jednostkami\n",
    "    layers.Activation('relu'),             # Aktywacja ReLU\n",
    "    layers.Dense(10, activation='softmax') # Warstwa wyjściowa z 10 klasami\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Wyświetlenie struktury modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99516b-473d-4a37-bbc4-afff62747d01",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3\n",
    "\n",
    "- Utwórz obiekt odpowiedniej funkcji straty oraz wybranego optymalizatora\n",
    "- Utwórz obiekty odpowiednich metryk, zarówno dla zbioru treningowego jak i testowego\n",
    "- Stworz funkcję do trenowania train_step(x,y) z wykorzystaniem obiektu tf.GradientTape, do monitorowania gradientów. Wykorzystaj funkcję \"gradient\" tego obiektu do wyznaczenia gradientów funkcji straty względem parametrów modelu (model.trainable_variables) oraz metodę \"apply_gradients\" optymalizatora do modyfikacji tych parametrów. Opatrz funkcję dekoratorem @tf.function\n",
    "- Utwórz podobną funkcję dla kroku testowania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\ipykernel_130896\\1823440784.py\", line 76, in <module>\n",
      "    loss = train_step(x_batch, y_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\__autograph_generated_file8xw7uc2i.py\", line 12, in tf__train_step\n",
      "    loss = ag__.converted_call(ag__.ld(loss_fn), (ag__.ld(y), ag__.ld(y_pred)), None, fscope)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n",
      "    losses = call_fn(y_true, y_pred)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 270, in call\n",
      "    return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n",
      "    return backend.sparse_categorical_crossentropy(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n",
      "    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\ipykernel_130896\\4284799304.py\", line 29, in train_step  *\n",
      "        loss = loss_fn(y, y_pred)\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 143, in __call__  **\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n",
      "        return backend.sparse_categorical_crossentropy(\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n",
      "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\n",
      "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(25088, 10)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1115, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Definicja modelu z warstwą Flatten\n",
    "class SimpleModel(Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.flatten = layers.Flatten()  # Dodajemy warstwę Flatten\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.dense2 = layers.Dense(10, activation='softmax')  # Warstwa wyjściowa dla klasyfikacji\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)  # Spłaszczenie wejścia\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Utwórz obiekt funkcji straty i optymalizatora\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)  # 'from_logits=False' ponieważ używamy softmax\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Utwórz obiekty metryk\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Funkcja do trenowania modelu (jeden krok)\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Obliczamy wyjście modelu i stratę\n",
    "        y_pred = model(x, training=True)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "\n",
    "    # Obliczamy gradienty\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Aktualizujemy wagi modelu\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Aktualizujemy metrykę dokładności dla treningu\n",
    "    train_acc_metric.update_state(y, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Funkcja do testowania modelu (jeden krok)\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    # Obliczamy wyjście modelu\n",
    "    y_pred = model(x, training=False)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "\n",
    "    # Aktualizujemy metrykę dokładności dla testu\n",
    "    test_acc_metric.update_state(y, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Przykładowe dane\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Przekształcamy dane w kształt [batch_size, 28, 28, 1] (dodajemy wymiar kanału)\n",
    "x_train = x_train[..., tf.newaxis]  # Dodanie wymiaru kanału\n",
    "x_test = x_test[..., tf.newaxis]    # Dodanie wymiaru kanału\n",
    "\n",
    "# Normalizacja danych wejściowych do zakresu [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Tworzymy model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Tworzymy Dataset dla treningu i testu\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# Trening - 1 epoka\n",
    "for epoch in range(1):\n",
    "    print(\"Start training\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds):\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy()}, Train Accuracy: {train_acc_metric.result().numpy()}\")\n",
    "\n",
    "    # Wyświetlamy dokładność treningową po epokach\n",
    "    print(f\"End of epoch {epoch}, Training Accuracy: {train_acc_metric.result().numpy()}\")\n",
    "\n",
    "# Testowanie - 1 epoka\n",
    "for epoch in range(1):\n",
    "    print(\"Start testing\")\n",
    "    for step, (x_batch, y_batch) in enumerate(test_ds):\n",
    "        loss = test_step(x_batch, y_batch)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Test Loss: {loss.numpy()}, Test Accuracy: {test_acc_metric.result().numpy()}\")\n",
    "\n",
    "    # Wyświetlamy dokładność testową po epokach\n",
    "    print(f\"End of epoch {epoch}, Test Accuracy: {test_acc_metric.result().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a477aa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9d0c596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "(32, 28, 28, 10)\n",
      "(32,)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\ipykernel_130896\\2561875056.py\", line 5, in <module>\n",
      "    loss = train_step(x_batch, y_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\__autograph_generated_fileth6bz7v8.py\", line 14, in tf__train_step\n",
      "    loss = ag__.converted_call(ag__.ld(loss_fn), (ag__.ld(y), ag__.ld(y_pred)), None, fscope)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n",
      "    losses = call_fn(y_true, y_pred)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 270, in call\n",
      "    return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n",
      "    return backend.sparse_categorical_crossentropy(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n",
      "    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\ipykernel_130896\\4112426723.py\", line 31, in train_step  *\n",
      "        loss = loss_fn(y, y_pred)\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 143, in __call__  **\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n",
      "        return backend.sparse_categorical_crossentropy(\n",
      "    File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n",
      "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\n",
      "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(25088, 10)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1115, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "# Trening - 1 epoka\n",
    "for epoch in range(1):\n",
    "    print(\"Start training\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds):\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        if step % 100 == 0:\n",
    "            # , Train Accuracy: {train_acc_metric.result().numpy()}, Loss: {loss}\n",
    "            print(f\"Step {step}\")\n",
    "\n",
    "    # # Wyświetlamy dokładność treningową po epokach\n",
    "    # print(f\"End of epoch {epoch}, Training Accuracy: {train_acc_metric.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31187c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testowanie - 1 epoka\n",
    "for epoch in range(1):\n",
    "    print(\"Start testing\")\n",
    "    for step, (x_batch, y_batch) in enumerate(test_ds):\n",
    "        loss = test_step(x_batch, y_batch)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Test Loss: {loss.numpy()}, Test Accuracy: {test_acc_metric.result().numpy()}\")\n",
    "\n",
    "    # Wyświetlamy dokładność testową po epokach\n",
    "    print(f\"End of epoch {epoch}, Test Accuracy: {test_acc_metric.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596174cd-62c2-4fc5-98eb-1a6ee22b9c5f",
   "metadata": {},
   "source": [
    "## Ćwiczenie 4\n",
    "\n",
    " - Zaimplementuj główną pętlę uczenia modelu dla zadanej liczby epok. Na starcie każdej epoki zresetuj ustawienia obiektów metryk (metodą reset_state), następnie wykonaj kroki uczenia na batchu ze zbioru treningowego oraz testowania na batchu ze zbioru testowego (wykorzystaj zbiory z ćwiczenia nr 1), oraz wyświetl lub zapisz do listy wyniki funkcji straty i dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bffeaf-fef5-4cd6-98be-0270781adcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ###################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243243b-f81f-430a-8917-cf97e51e3d5e",
   "metadata": {},
   "source": [
    "# OPTYMALIZACJA HIPERPARAMETRÓW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a33caa-8309-4b51-a13a-504a41bdf0dc",
   "metadata": {},
   "source": [
    "## Ćwiczenie 5\n",
    "\n",
    "- zaimportuj pakiet keras-tuner \n",
    "- Utwórz klasę dziedziczącą po klasie kt.HyperModel (https://keras.io/api/keras_tuner/hypermodels/), której metodą jest metoda def build(self, hp), zwracająca model generowany (i skompilowany) z wykorzystaniem frameworku Keras. parametr \"hp\" pozwala na definiowanie przedziałów poszukiwań parametrów modelu (np. liczby neuronów w warstwie)\n",
    "- Utwórz obiekt tunera (np. kt.RandomSearch, https://keras.io/api/keras_tuner/tuners/) \n",
    "- Naucz model i znajdź optymalne wartości hiperparametrów metodą tuner.search (przyjmuje takie same parametry jak metoda \"fit\" przy trenowaniu modeli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc219ac-a3bc-44d5-96d0-697ee2315e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class .....(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "    model = ####################\n",
    "    model.compile(#########)\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(nazwa klasy(),\n",
    "    objective='val_loss',\n",
    "    max_trials=##)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
